{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a009d287506ce357",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T19:29:58.774889Z",
     "start_time": "2023-11-16T19:29:58.754884300Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names = ['1755_Lisbon_earthquake','1896_Summer_Olympics','1997_Pacific_hurricane_season','Actinium','Barracuda','Basketball','Bath_School_disaster','Chicago','Chocolate','Diamond','Dice','Drinking_water','Duchenne_muscular_dystrophy','Geography_of_Ireland','Giraffe','Gunpowder','Osama_bin_Laden','Palm_oil','Peace','Pellagra','Phishing','Plant','Plato','Pneumonia','Poison_gas_in_World_War_I','Politics','Pollution','Red_Kite','Rice','Rio_de_Janeiro','Romeo_and_Juliet','Rugby_World_Cup','Rwandan_Genocide','Santa_Claus','Scooby-Doo']\n",
    "len(file_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d4e82276cd12d5e",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### MODEL DESCRIPTION\n",
    "Pattern is a multipurpose library that is capable of handling NLP operations, data mining, machine learning etc. It also contains sentiment analysis functionality which is suitable for our task.\n",
    "The `sentiment` function under `pattern.text.en` module is used to calculate the sentiment of a given text, it takes a sentence as input which can also be a string, Synset, word or document, and returns a (polarity, subjectivity)-tuple with polarity between -1.0 and +1.0 and subjectivity between 0.0 and 1.0. polarity describes the emotional leaning of the text, while subjectivity describes the strength of such emotion.\n",
    "\n",
    "In our usage the input is a string of the entire article loaded from the Wikispeedia dataset, In this case, it first tokenizes the text into words(punctuation, space and abbreviations are handled at this stage), then it Lowercases each word because sentiment analysis is case insensitive. Next it calculates the sentiment of each word by consulting the predefined sentiment [dictionary](https://github.com/clips/pattern/blob/master/pattern/text/en/en-sentiment.xml)(modifiers and negations are also considered at this time). Finally it returns the average of all the words as the sentiment of the text.\n",
    "\n",
    "Pattern is a classic and well-known non-commercial library for the sentiment analysis task solution, the module itself lasts over 10 years and has 8.6k stars on github. It provides detailed results (polarity and subjectivity) for many mainstream languages, and its API is fast and easy to use with other NLP preprocessing tools embedded. More details can be found in the [official documentation](https://digiasset.org/html/pattern.html) and [repository](https://digiasset.org/html/pattern.html).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d3ea67375c6063",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### METHOD && RESULTS\n",
    "Each selected article is loaded and feeded into the `sentiment` function, the polarity is then printed out. The results are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-16T20:00:33.496654Z",
     "start_time": "2023-11-16T20:00:32.689208900Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1755_Lisbon_earthquake: 0.0816923282902664\n",
      "1896_Summer_Olympics: 0.11173071331653418\n",
      "1997_Pacific_hurricane_season: 0.051366249491249474\n",
      "Actinium: 0.03542682926829269\n",
      "Barracuda: 0.1132213321465658\n",
      "Basketball: 0.08600218021995364\n",
      "Bath_School_disaster: 0.010679336219336222\n",
      "Chicago: 0.10564842500695483\n",
      "Chocolate: 0.07674311830989919\n",
      "Diamond: 0.12359236785162714\n",
      "Dice: -0.0001423413188119043\n",
      "Drinking_water: 0.12155415214866433\n",
      "Duchenne_muscular_dystrophy: 0.051342562953478464\n",
      "Geography_of_Ireland: 0.06101678376268537\n",
      "Giraffe: 0.04892030793508625\n",
      "Gunpowder: 0.01667841269841271\n",
      "Osama_bin_Laden: 0.04482218734525007\n",
      "Palm_oil: 0.10377811870669014\n",
      "Peace: 0.07109719189365207\n",
      "Pellagra: 0.013132859204287773\n",
      "Phishing: 0.03130031080031078\n",
      "Plant: 0.09383068133068131\n",
      "Plato: 0.16051446416831025\n",
      "Pneumonia: 0.05341062158293232\n",
      "Poison_gas_in_World_War_I: 0.08464027042373903\n",
      "Politics: 0.10395405509821987\n",
      "Pollution: 0.08715013543960917\n",
      "Red_Kite: 0.035212025919573085\n",
      "Rice: 0.08478642004761416\n",
      "Rio_de_Janeiro: 0.15940676171654442\n",
      "Romeo_and_Juliet: 0.08846829977782353\n",
      "Rugby_World_Cup: 0.09477842945584883\n",
      "Rwandan_Genocide: 0.05457812020169003\n",
      "Santa_Claus: 0.08992885441238731\n",
      "Scooby-Doo: 0.1352173090752449\n"
     ]
    }
   ],
   "source": [
    "from pattern.text.en import sentiment\n",
    "\n",
    "for file_name in file_names:\n",
    "    with open('data/plaintext_articles/'+file_name+'.txt', 'r', encoding='utf-8') as file:\n",
    "        data = file.read()\n",
    "        polarity, subjectivity = sentiment(data)\n",
    "        print(f\"{file_name}: {polarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f3d2e93592f5b7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "The MSE is compared with the human labeled result(trinary value among -1 0 1) which is around **0.7**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0a56420f2a39333",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### DISCUSSION\n",
    "The performance of this model is generally not good compared to other models we tested, the possible reason could be that it uses a fixed sentiment dictionary which may contain bias between different domains. It's observed that the model tends to give a very small value between [0,0.1] despite the articles, a reason could be that Wikipedia articles are designed to be neutral and objective, It generally looks at problems dialectically and rarely produces strong emotions. However, in the range of this project, we care more about the sentiment level of the article (the word itself) rather than the way it is written, the model considers all the words on the page evenly and thus may produce results that are not what we expect.\n",
    "\n",
    "This is not the optimal model for our task, a ML-based approach is generally more flexible and powerful in this case."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
